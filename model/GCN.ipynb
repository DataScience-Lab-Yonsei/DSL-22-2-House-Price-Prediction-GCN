{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_AGJKLgTio5","executionInfo":{"status":"ok","timestamp":1665311602008,"user_tz":-540,"elapsed":16890,"user":{"displayName":"박지호(공과대학 전기전자공학)","userId":"16992648500508297386"}},"outputId":"c2487019-e8fd-4746-86d0-3de2cdeb6c82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["! pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.12.0+cu113.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w9Pm-TtSjbEk","executionInfo":{"status":"ok","timestamp":1665311582135,"user_tz":-540,"elapsed":8534,"user":{"displayName":"박지호(공과대학 전기전자공학)","userId":"16992648500508297386"}},"outputId":"17985ee4-214a-47c4-f2cc-76452915d7a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.pyg.org/whl/torch-1.12.0+cu113.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n","\u001b[K     |████████████████████████████████| 7.9 MB 5.3 MB/s \n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 73.1 MB/s \n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.4 MB)\n","\u001b[K     |████████████████████████████████| 2.4 MB 80.4 MB/s \n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (709 kB)\n","\u001b[K     |████████████████████████████████| 709 kB 73.9 MB/s \n","\u001b[?25hCollecting torch-geometric\n","  Downloading torch_geometric-2.1.0.post1.tar.gz (467 kB)\n","\u001b[K     |████████████████████████████████| 467 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.9.24)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.1.0.post1-py3-none-any.whl size=689859 sha256=a095076d031ae46e73f4b36d4e988cdbda799e61f70eb2391e10e0f5dcfc898d\n","  Stored in directory: /root/.cache/pip/wheels/d1/cb/43/f7f2e472de4d7cff31bceddadc36d634e1e545fbc17961c282\n","Successfully built torch-geometric\n","Installing collected packages: torch-spline-conv, torch-sparse, torch-scatter, torch-geometric, torch-cluster\n","Successfully installed torch-cluster-1.6.0 torch-geometric-2.1.0.post1 torch-scatter-2.0.9 torch-sparse-0.6.15 torch-spline-conv-1.2.1\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","from tqdm import tqdm\n","from random import randint\n","import torch.nn as nn\n","from sklearn.preprocessing import StandardScaler\n","import torch\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","device = torch.device('cuda:0')\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pMtt2oA27UMo","executionInfo":{"status":"ok","timestamp":1665311605297,"user_tz":-540,"elapsed":3291,"user":{"displayName":"박지호(공과대학 전기전자공학)","userId":"16992648500508297386"}},"outputId":"747a476c-eeaa-4634-c30f-6ffcee6924eb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["train_pre = pd.read_csv('/content/drive/Shareddrives/DSL_Modeling_E/Real_Estate/data/...')\n","test_pre = pd.read_csv('/content/drive/Shareddrives/DSL_Modeling_E/Real_Estate/data/...')"],"metadata":{"id":"15EZIxdv7P8K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_pre[['gu']].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kd9EqyD5AwSY","executionInfo":{"status":"ok","timestamp":1665311607630,"user_tz":-540,"elapsed":4,"user":{"displayName":"박지호(공과대학 전기전자공학)","userId":"16992648500508297386"}},"outputId":"b47e8c47-df78-4531-8cfc-3332932c3bf8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["gu          \n","gangseo         4097\n","guro            3983\n","yeongdeungpo    3970\n","seocho          3950\n","nowon           3902\n","songpa          3896\n","yangcheon       3886\n","guemcheon       3881\n","eunpyeong       3833\n","dobong          3784\n","gangdong        3783\n","dongjak         3748\n","mapo            3742\n","jungnang        3725\n","seongdong       3705\n","seongbuk        3703\n","gwangjin        3689\n","yongsan         3688\n","dongdaemun      3678\n","gangnam         3664\n","seodaemun       3661\n","gwanak          3651\n","jung            3625\n","gangbuk         3433\n","jongno          3152\n","dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["train_pre = train_pre[train_pre['gu'].isin(['gangnam','seocho'])]\n","test_pre = test_pre[test_pre['gu'].isin(['gangnam','seocho'])]"],"metadata":{"id":"C0GiLnnX7M9g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def Preprocess (train,test):\n","  # 필요없는 column drop\n","  train.drop(['Unnamed: 0','id','tagList','tag'],axis=1,inplace =True)\n","  test.drop(['Unnamed: 0','id','tagList','tag'],axis=1,inplace=True)\n","  # Normalization Fit (아직 transform은 안함)\n","\n","  # scaler = StandardScaler()\n","  # scaler = scaler.fit(train.drop(['gu'],axis=1).iloc[:,:6])\n","  # # X, y 분리\n","  ten = torch.tensor(train.drop(['gu'],axis=1).iloc[:,:6].to_numpy())\n","  mean = ten.mean(dim=0)\n","  std = ten.mean(dim=0)\n","  mean ,std = mean.to(device), std.to(device)\n","\n","\n","  return train, test, mean, std\n","\n","\n","def adjacent_matrix(data):\n","  n = len(data)\n","  A = torch.tensor([0,0]).reshape(2,1)\n","\n","  dist = (data[:,:2]*100)\n","\n","  \n","  for i in range(0,n):\n","    for j in range(0,i):\n","      if i != j:\n","        a = (dist[i] - dist[j]).abs().sum()\n","        if a <= 0.2:\n","          A = torch.cat((A,torch.tensor([i,j]).reshape(2,1),torch.tensor([j,i]).reshape(2,1)),dim=1 )\n","  A = A[:,1:]\n","  \n","  return A.to(device)"],"metadata":{"id":"mFvZzFFiJH_2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# column 필요없는거 제거된 게 필요함!\n","\n","class Graph_data(Dataset):\n","  def __init__(self, data, n):\n","    self.GU = data['gu'].unique()\n","    self.gu = []\n","    self.x = []\n","    self.y = []\n","    self.first = True\n","\n","    for i in tqdm(range(n)):\n","      for gu in self.GU:\n","        #데이터의 구 \n","        self.gu.append(gu)\n","        df = data[data['gu'] ==gu].sample(randint(1000,1300))\n","        a = torch.tensor(df.drop(['gu','deposit','monthlyPay'],axis =1).to_numpy(),dtype = torch.float).unsqueeze(0)\n","        b = torch.tensor(df[['deposit','monthlyPay']].to_numpy(),dtype = torch.float).unsqueeze(0)\n","        self.x.append(a)\n","        self.y.append(b)\n","\n","        \n","  def __len__(self):\n","    return len(self.x)\n","\n","  def __getitem__(self, idx):\n","    return self.x[idx], self.y[idx]\n","    #  self.gu[idx]"],"metadata":{"id":"tUUqAcOlPT4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train, test,mean,std = Preprocess(train_pre,test_pre)"],"metadata":{"id":"qDuAMUwXYHS7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test.drop('Unnamed: 0.1',axis=1,inplace=True)"],"metadata":{"id":"PA3_FnZz1tqE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = Graph_data(train,500)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mm3OAT8dau1o","executionInfo":{"status":"ok","timestamp":1665311663502,"user_tz":-540,"elapsed":3012,"user":{"displayName":"박지호(공과대학 전기전자공학)","userId":"16992648500508297386"}},"outputId":"5aa7d1cf-52c6-43ab-d30a-7ffea45f2f45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:02<00:00, 171.75it/s]\n"]}]},{"cell_type":"code","source":["testset = Graph_data(test,100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epEHh3jsgZLO","executionInfo":{"status":"ok","timestamp":1665311664127,"user_tz":-540,"elapsed":636,"user":{"displayName":"박지호(공과대학 전기전자공학)","userId":"16992648500508297386"}},"outputId":"5016a79a-de2e-4488-9177-8f854ab31ca9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [00:00<00:00, 216.67it/s]\n"]}]},{"cell_type":"code","source":["class Model (nn.Module):\n","    def __init__(self,init_features,final_features):\n","        super(Model, self).__init__()\n","        # One-hot feature들 중 embedding 거칠 layer\n","        self.emb_goods = nn.Linear(11,5)\n","        self.emb_direc = nn.Linear(8,2)\n","        # GCN Conv Layer\n","        self.conv1 = GCNConv(init_features, 24)  # 처음 GCN에 넣어 줄 feature 수 \n","        self.conv2 = GCNConv(24, final_features)  # 마지막으로 설정 할 feature 수\n","        # GCN 거친 Embedding이 들어갈 fc Layer\n","        self.fc1 = nn.Linear(final_features,15)\n","        self.fc2 = nn.Linear(15,10)\n","        self.fc3 = nn.Linear(10,5)\n","        self.fc4 = nn.Linear(5,3)\n","        #self.fc5 = nn.Linear(15,10)\n","        #self.fc6 = nn.Linear(10,5)\n","        #self.fc7 = nn.Linear(5,3)\n","        # Deposit Output Layer\n","        self.depos_output = nn.Linear(3,1)\n","        # Monthly Output Layer\n","        self.month_output = nn.Linear(4,1)\n","        # Activation Func\n","        self.ReLU = nn.ReLU()\n","\n","\n","    def forward(self,x,edge_index):\n","        \n","        # Split Input Features\n","        x_goods = x[:,-19:-8] # 확인해보기\n","        x_direc = x[:,-8:]\n","        x_raw = x[:,:-19]\n","\n","        # Feature Embedding (One-hot features)\n","        emb1 = self.emb_goods(x_goods)\n","        emb2 = self.emb_direc(x_direc)\n","\n","        # GCN Forward\n","        y = self.conv1(torch.cat((x_raw,emb1,emb2),1), edge_index)\n","        y = F.relu(y)\n","        y = F.dropout(y,0.2)\n","        y = self.conv2(y, edge_index)\n","\n","        # fc Forward\n","        o = self.fc1(y)\n","        o = self.fc2(o)\n","        o = self.fc3(o)\n","        o = self.fc4(o)\n","        #o = self.fc5(o)\n","        #o = self.fc6(o)\n","        #o = self.fc7(o)\n","\n","        # Deposit Out\n","        dep = self.depos_output(o)\n","\n","        # Month Out\n","        mon = self.month_output(torch.cat((o,dep),1))\n","\n","        return torch.cat((dep,mon),1)"],"metadata":{"id":"6CZa_F6QfGIr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["k =6 # Non ONe-hot features\n","model = Model(11+k,20).to(device)\n","# data = dataset[0].to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)#, weight_decay=5e-4)\n","criterion = nn.MSELoss().to(device) "],"metadata":{"id":"pqvT-CsVh_YP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seq_train_loss = []"],"metadata":{"id":"GsElNZzxihdA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train Def\n","\n","def train_(epoch):\n","    print(f'\\n[ Train epoch: {epoch+1} ]')\n","\n","    model.train() \n","\n","    running_loss = 0.0\n","    batch_losses = []\n","\n","    for batch_idx, (inputs, targets) in enumerate(train_dataloader):\n","        inputs, targets = inputs.to(device), targets.to(device) \n","\n","        # Adjacent Matrix 구하기\n","        adjacent = adjacent_matrix(inputs)\n","\n","        # Scaler 적용\n","\n","        # a = inputs.squeeze()[:,:6].clone().detach()\n","        # a = (a - mean)/std\n","        inputs[0,0,:,:6] = (inputs.squeeze()[:,:6] -mean)/std.unsqueeze(0).unsqueeze(0)\n","\n","        # DL 학습 기본 코드\n","        optimizer.zero_grad() \n","        outputs = model(inputs.squeeze(0).squeeze(0),adjacent) \n","        loss = criterion(outputs, targets) \n","        loss.backward() \n","        optimizer.step() \n","\n","        running_loss += loss.item()\n","        batch_losses.append(loss.item())\n","        \n","        if batch_idx % 200 == 199:\n","            print(f'\\nCurrent batch: {str(batch_idx+1)}')\n","            print(f'Average train loss of recent 1 batches: {running_loss / 200}') \n","            running_loss = 0.0\n","\n","    avg_loss = sum(batch_losses) / len(batch_losses)\n","    seq_train_loss.append(avg_loss)\n","    print('Total train loss:', avg_loss)"],"metadata":{"id":"oq5IkUWyfPpk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seq_test_loss=[]"],"metadata":{"id":"UkOlzDwxnqAw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test Def\n","\n","def test_(epoch):\n","    print(f'\\n[ Test epoch: {epoch+1} ]')\n","\n","    model.eval() \n","\n","    loss = 0\n","    batch_losses = []\n","\n","    with torch.no_grad(): \n","        for batch_idx, (inputs, targets) in enumerate(test_dataloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            # Adjacent \n","            adjacent = adjacent_matrix(inputs)\n","\n","            # Scaler 적용\n","            inputs[0,0,:,:6] = (inputs.squeeze()[:,:6] -mean)/std.unsqueeze(0).unsqueeze(0)\n","\n","            \n","            outputs = model(inputs.squeeze(0).squeeze(0),adjacent)\n","            loss = criterion(outputs, targets)\n","            batch_losses.append(loss.item())\n","\n","    avg_loss = sum(batch_losses) / len(batch_losses)\n","    seq_test_loss.append(avg_loss)\n","    print('Test average loss:', avg_loss)"],"metadata":{"id":"B0TgJ-S_fPmG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader =DataLoader(dataset,batch_size=1, shuffle = False)\n","test_dataloader = DataLoader(testset,batch_size=1, shuffle = False)"],"metadata":{"id":"5y8STcT-kXOp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testset[0][0][0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5cYZZ6XDpNj","executionInfo":{"status":"ok","timestamp":1665034929728,"user_tz":-540,"elapsed":581,"user":{"displayName":"namhun kim","userId":"12332195563700468765"}},"outputId":"d06f79f9-b84c-4eff-e095-48a266d59885"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1049, 30])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["train.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4EYtaq-n0jjh","executionInfo":{"status":"ok","timestamp":1665036997351,"user_tz":-540,"elapsed":1,"user":{"displayName":"namhun kim","userId":"12332195563700468765"}},"outputId":"df14315f-49bb-4b74-baee-719a3f13fead"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['lat', 'lng', 'gu', 'floor', 'floor_total', 'contractArea', 'realArea',\n","       'deposit', 'monthlyPay', 'payType_단기임대', 'payType_매매', 'payType_월세',\n","       'payType_전세', 'goodsType_단독/다가구', 'goodsType_빌라', 'goodsType_사무실',\n","       'goodsType_상가', 'goodsType_상가주택', 'goodsType_아파트', 'goodsType_오피스텔',\n","       'goodsType_원룸', 'goodsType_재개발', 'goodsType_재건축/아파트분양권',\n","       'goodsType_지식산업센터', 'direction_남동향', 'direction_남서향', 'direction_남향',\n","       'direction_동향', 'direction_북동향', 'direction_북서향', 'direction_북향',\n","       'direction_서향'],\n","      dtype='object')"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["test.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BJnK_UL_0M8G","executionInfo":{"status":"ok","timestamp":1665036998824,"user_tz":-540,"elapsed":2,"user":{"displayName":"namhun kim","userId":"12332195563700468765"}},"outputId":"07fc427d-0f1f-4fbd-b1b8-6856c20dfba4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['lat', 'lng', 'gu', 'floor', 'floor_total', 'contractArea', 'realArea',\n","       'deposit', 'monthlyPay', 'payType_단기임대', 'payType_매매', 'payType_월세',\n","       'payType_전세', 'goodsType_단독/다가구', 'goodsType_빌라', 'goodsType_사무실',\n","       'goodsType_상가', 'goodsType_상가주택', 'goodsType_아파트', 'goodsType_오피스텔',\n","       'goodsType_원룸', 'goodsType_재개발', 'goodsType_재건축/아파트분양권',\n","       'goodsType_지식산업센터', 'direction_남동향', 'direction_남서향', 'direction_남향',\n","       'direction_동향', 'direction_북동향', 'direction_북서향', 'direction_북향',\n","       'direction_서향'],\n","      dtype='object')"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["epochs = 50\n","for i in range(0,epochs):\n","  train_(i)\n","  test_(i) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z3Zkh3yOfPiY","executionInfo":{"status":"ok","timestamp":1665048743311,"user_tz":-540,"elapsed":506042,"user":{"displayName":"namhun kim","userId":"12332195563700468765"}},"outputId":"e034c133-7761-4692-bb58-d3087fd6c501"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[ Train epoch: 1 ]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1277, 2])) that is different to the input size (torch.Size([1277, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1006, 2])) that is different to the input size (torch.Size([1006, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1294, 2])) that is different to the input size (torch.Size([1294, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1204, 2])) that is different to the input size (torch.Size([1204, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1014, 2])) that is different to the input size (torch.Size([1014, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1013, 2])) that is different to the input size (torch.Size([1013, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1039, 2])) that is different to the input size (torch.Size([1039, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1097, 2])) that is different to the input size (torch.Size([1097, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1138, 2])) that is different to the input size (torch.Size([1138, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1092, 2])) that is different to the input size (torch.Size([1092, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1115, 2])) that is different to the input size (torch.Size([1115, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1285, 2])) that is different to the input size (torch.Size([1285, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1105, 2])) that is different to the input size (torch.Size([1105, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1041, 2])) that is different to the input size (torch.Size([1041, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1034, 2])) that is different to the input size (torch.Size([1034, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1110, 2])) that is different to the input size (torch.Size([1110, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1195, 2])) that is different to the input size (torch.Size([1195, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1096, 2])) that is different to the input size (torch.Size([1096, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1202, 2])) that is different to the input size (torch.Size([1202, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1180, 2])) that is different to the input size (torch.Size([1180, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1206, 2])) that is different to the input size (torch.Size([1206, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1258, 2])) that is different to the input size (torch.Size([1258, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1159, 2])) that is different to the input size (torch.Size([1159, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1126, 2])) that is different to the input size (torch.Size([1126, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1035, 2])) that is different to the input size (torch.Size([1035, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1225, 2])) that is different to the input size (torch.Size([1225, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1269, 2])) that is different to the input size (torch.Size([1269, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1100, 2])) that is different to the input size (torch.Size([1100, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1173, 2])) that is different to the input size (torch.Size([1173, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1200, 2])) that is different to the input size (torch.Size([1200, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1230, 2])) that is different to the input size (torch.Size([1230, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1018, 2])) that is different to the input size (torch.Size([1018, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1081, 2])) that is different to the input size (torch.Size([1081, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1161, 2])) that is different to the input size (torch.Size([1161, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1028, 2])) that is different to the input size (torch.Size([1028, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1060, 2])) that is different to the input size (torch.Size([1060, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1238, 2])) that is different to the input size (torch.Size([1238, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1032, 2])) that is different to the input size (torch.Size([1032, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1179, 2])) that is different to the input size (torch.Size([1179, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1007, 2])) that is different to the input size (torch.Size([1007, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1002, 2])) that is different to the input size (torch.Size([1002, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1011, 2])) that is different to the input size (torch.Size([1011, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1248, 2])) that is different to the input size (torch.Size([1248, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1246, 2])) that is different to the input size (torch.Size([1246, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1094, 2])) that is different to the input size (torch.Size([1094, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1263, 2])) that is different to the input size (torch.Size([1263, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1299, 2])) that is different to the input size (torch.Size([1299, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1226, 2])) that is different to the input size (torch.Size([1226, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1143, 2])) that is different to the input size (torch.Size([1143, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1071, 2])) that is different to the input size (torch.Size([1071, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1064, 2])) that is different to the input size (torch.Size([1064, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1267, 2])) that is different to the input size (torch.Size([1267, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1036, 2])) that is different to the input size (torch.Size([1036, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1108, 2])) that is different to the input size (torch.Size([1108, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1030, 2])) that is different to the input size (torch.Size([1030, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1188, 2])) that is different to the input size (torch.Size([1188, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1061, 2])) that is different to the input size (torch.Size([1061, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1047, 2])) that is different to the input size (torch.Size([1047, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1288, 2])) that is different to the input size (torch.Size([1288, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1015, 2])) that is different to the input size (torch.Size([1015, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1281, 2])) that is different to the input size (torch.Size([1281, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1076, 2])) that is different to the input size (torch.Size([1076, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1042, 2])) that is different to the input size (torch.Size([1042, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1272, 2])) that is different to the input size (torch.Size([1272, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1048, 2])) that is different to the input size (torch.Size([1048, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1136, 2])) that is different to the input size (torch.Size([1136, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1090, 2])) that is different to the input size (torch.Size([1090, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1240, 2])) that is different to the input size (torch.Size([1240, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1101, 2])) that is different to the input size (torch.Size([1101, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1229, 2])) that is different to the input size (torch.Size([1229, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1057, 2])) that is different to the input size (torch.Size([1057, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1137, 2])) that is different to the input size (torch.Size([1137, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1292, 2])) that is different to the input size (torch.Size([1292, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1080, 2])) that is different to the input size (torch.Size([1080, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1118, 2])) that is different to the input size (torch.Size([1118, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1093, 2])) that is different to the input size (torch.Size([1093, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1167, 2])) that is different to the input size (torch.Size([1167, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1012, 2])) that is different to the input size (torch.Size([1012, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1000, 2])) that is different to the input size (torch.Size([1000, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1262, 2])) that is different to the input size (torch.Size([1262, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1053, 2])) that is different to the input size (torch.Size([1053, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1234, 2])) that is different to the input size (torch.Size([1234, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1059, 2])) that is different to the input size (torch.Size([1059, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1209, 2])) that is different to the input size (torch.Size([1209, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1157, 2])) that is different to the input size (torch.Size([1157, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1106, 2])) that is different to the input size (torch.Size([1106, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1228, 2])) that is different to the input size (torch.Size([1228, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1079, 2])) that is different to the input size (torch.Size([1079, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1111, 2])) that is different to the input size (torch.Size([1111, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1282, 2])) that is different to the input size (torch.Size([1282, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1284, 2])) that is different to the input size (torch.Size([1284, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1040, 2])) that is different to the input size (torch.Size([1040, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1134, 2])) that is different to the input size (torch.Size([1134, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1205, 2])) that is different to the input size (torch.Size([1205, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1127, 2])) that is different to the input size (torch.Size([1127, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1221, 2])) that is different to the input size (torch.Size([1221, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1124, 2])) that is different to the input size (torch.Size([1124, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1089, 2])) that is different to the input size (torch.Size([1089, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1037, 2])) that is different to the input size (torch.Size([1037, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1052, 2])) that is different to the input size (torch.Size([1052, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1222, 2])) that is different to the input size (torch.Size([1222, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1056, 2])) that is different to the input size (torch.Size([1056, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1186, 2])) that is different to the input size (torch.Size([1186, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1132, 2])) that is different to the input size (torch.Size([1132, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1259, 2])) that is different to the input size (torch.Size([1259, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1270, 2])) that is different to the input size (torch.Size([1270, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1207, 2])) that is different to the input size (torch.Size([1207, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1120, 2])) that is different to the input size (torch.Size([1120, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1038, 2])) that is different to the input size (torch.Size([1038, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1162, 2])) that is different to the input size (torch.Size([1162, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1196, 2])) that is different to the input size (torch.Size([1196, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1072, 2])) that is different to the input size (torch.Size([1072, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1273, 2])) that is different to the input size (torch.Size([1273, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1174, 2])) that is different to the input size (torch.Size([1174, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1141, 2])) that is different to the input size (torch.Size([1141, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1027, 2])) that is different to the input size (torch.Size([1027, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1083, 2])) that is different to the input size (torch.Size([1083, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1252, 2])) that is different to the input size (torch.Size([1252, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1023, 2])) that is different to the input size (torch.Size([1023, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1257, 2])) that is different to the input size (torch.Size([1257, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1291, 2])) that is different to the input size (torch.Size([1291, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1198, 2])) that is different to the input size (torch.Size([1198, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1109, 2])) that is different to the input size (torch.Size([1109, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1121, 2])) that is different to the input size (torch.Size([1121, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1295, 2])) that is different to the input size (torch.Size([1295, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1231, 2])) that is different to the input size (torch.Size([1231, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1224, 2])) that is different to the input size (torch.Size([1224, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1298, 2])) that is different to the input size (torch.Size([1298, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1250, 2])) that is different to the input size (torch.Size([1250, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1150, 2])) that is different to the input size (torch.Size([1150, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1233, 2])) that is different to the input size (torch.Size([1233, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1260, 2])) that is different to the input size (torch.Size([1260, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1087, 2])) that is different to the input size (torch.Size([1087, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1104, 2])) that is different to the input size (torch.Size([1104, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1274, 2])) that is different to the input size (torch.Size([1274, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1031, 2])) that is different to the input size (torch.Size([1031, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1218, 2])) that is different to the input size (torch.Size([1218, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1255, 2])) that is different to the input size (torch.Size([1255, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1190, 2])) that is different to the input size (torch.Size([1190, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1074, 2])) that is different to the input size (torch.Size([1074, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1178, 2])) that is different to the input size (torch.Size([1178, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1004, 2])) that is different to the input size (torch.Size([1004, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1075, 2])) that is different to the input size (torch.Size([1075, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1065, 2])) that is different to the input size (torch.Size([1065, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1220, 2])) that is different to the input size (torch.Size([1220, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1227, 2])) that is different to the input size (torch.Size([1227, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1153, 2])) that is different to the input size (torch.Size([1153, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1044, 2])) that is different to the input size (torch.Size([1044, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1165, 2])) that is different to the input size (torch.Size([1165, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1166, 2])) that is different to the input size (torch.Size([1166, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1191, 2])) that is different to the input size (torch.Size([1191, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1171, 2])) that is different to the input size (torch.Size([1171, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1235, 2])) that is different to the input size (torch.Size([1235, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1286, 2])) that is different to the input size (torch.Size([1286, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1068, 2])) that is different to the input size (torch.Size([1068, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Current batch: 200\n","Average train loss of recent 1 batches: 2631114322.88\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1070, 2])) that is different to the input size (torch.Size([1070, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1148, 2])) that is different to the input size (torch.Size([1148, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1181, 2])) that is different to the input size (torch.Size([1181, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1254, 2])) that is different to the input size (torch.Size([1254, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1176, 2])) that is different to the input size (torch.Size([1176, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1192, 2])) that is different to the input size (torch.Size([1192, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1102, 2])) that is different to the input size (torch.Size([1102, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1256, 2])) that is different to the input size (torch.Size([1256, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1211, 2])) that is different to the input size (torch.Size([1211, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1139, 2])) that is different to the input size (torch.Size([1139, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1194, 2])) that is different to the input size (torch.Size([1194, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1243, 2])) that is different to the input size (torch.Size([1243, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1024, 2])) that is different to the input size (torch.Size([1024, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1144, 2])) that is different to the input size (torch.Size([1144, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1019, 2])) that is different to the input size (torch.Size([1019, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1199, 2])) that is different to the input size (torch.Size([1199, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1005, 2])) that is different to the input size (torch.Size([1005, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1091, 2])) that is different to the input size (torch.Size([1091, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1236, 2])) that is different to the input size (torch.Size([1236, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1247, 2])) that is different to the input size (torch.Size([1247, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1177, 2])) that is different to the input size (torch.Size([1177, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1265, 2])) that is different to the input size (torch.Size([1265, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1043, 2])) that is different to the input size (torch.Size([1043, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1066, 2])) that is different to the input size (torch.Size([1066, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1154, 2])) that is different to the input size (torch.Size([1154, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1208, 2])) that is different to the input size (torch.Size([1208, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1266, 2])) that is different to the input size (torch.Size([1266, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1021, 2])) that is different to the input size (torch.Size([1021, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1082, 2])) that is different to the input size (torch.Size([1082, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1001, 2])) that is different to the input size (torch.Size([1001, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1095, 2])) that is different to the input size (torch.Size([1095, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1058, 2])) that is different to the input size (torch.Size([1058, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1025, 2])) that is different to the input size (torch.Size([1025, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1152, 2])) that is different to the input size (torch.Size([1152, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1129, 2])) that is different to the input size (torch.Size([1129, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1279, 2])) that is different to the input size (torch.Size([1279, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1169, 2])) that is different to the input size (torch.Size([1169, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1213, 2])) that is different to the input size (torch.Size([1213, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1008, 2])) that is different to the input size (torch.Size([1008, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1253, 2])) that is different to the input size (torch.Size([1253, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1217, 2])) that is different to the input size (torch.Size([1217, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1099, 2])) that is different to the input size (torch.Size([1099, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1112, 2])) that is different to the input size (torch.Size([1112, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1009, 2])) that is different to the input size (torch.Size([1009, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1145, 2])) that is different to the input size (torch.Size([1145, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1296, 2])) that is different to the input size (torch.Size([1296, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1245, 2])) that is different to the input size (torch.Size([1245, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1300, 2])) that is different to the input size (torch.Size([1300, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1088, 2])) that is different to the input size (torch.Size([1088, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1184, 2])) that is different to the input size (torch.Size([1184, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1219, 2])) that is different to the input size (torch.Size([1219, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1237, 2])) that is different to the input size (torch.Size([1237, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1193, 2])) that is different to the input size (torch.Size([1193, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1113, 2])) that is different to the input size (torch.Size([1113, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1187, 2])) that is different to the input size (torch.Size([1187, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1022, 2])) that is different to the input size (torch.Size([1022, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1119, 2])) that is different to the input size (torch.Size([1119, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1147, 2])) that is different to the input size (torch.Size([1147, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1046, 2])) that is different to the input size (torch.Size([1046, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1289, 2])) that is different to the input size (torch.Size([1289, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1239, 2])) that is different to the input size (torch.Size([1239, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1114, 2])) that is different to the input size (torch.Size([1114, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1249, 2])) that is different to the input size (torch.Size([1249, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1125, 2])) that is different to the input size (torch.Size([1125, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1073, 2])) that is different to the input size (torch.Size([1073, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1168, 2])) that is different to the input size (torch.Size([1168, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1122, 2])) that is different to the input size (torch.Size([1122, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1203, 2])) that is different to the input size (torch.Size([1203, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1063, 2])) that is different to the input size (torch.Size([1063, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1215, 2])) that is different to the input size (torch.Size([1215, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1182, 2])) that is different to the input size (torch.Size([1182, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1261, 2])) that is different to the input size (torch.Size([1261, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1283, 2])) that is different to the input size (torch.Size([1283, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Current batch: 400\n","Average train loss of recent 1 batches: 1403270079.68\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1128, 2])) that is different to the input size (torch.Size([1128, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1020, 2])) that is different to the input size (torch.Size([1020, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1170, 2])) that is different to the input size (torch.Size([1170, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1287, 2])) that is different to the input size (torch.Size([1287, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1185, 2])) that is different to the input size (torch.Size([1185, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1029, 2])) that is different to the input size (torch.Size([1029, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1054, 2])) that is different to the input size (torch.Size([1054, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1069, 2])) that is different to the input size (torch.Size([1069, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1212, 2])) that is different to the input size (torch.Size([1212, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1183, 2])) that is different to the input size (torch.Size([1183, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1051, 2])) that is different to the input size (torch.Size([1051, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1244, 2])) that is different to the input size (torch.Size([1244, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1049, 2])) that is different to the input size (torch.Size([1049, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1155, 2])) that is different to the input size (torch.Size([1155, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1241, 2])) that is different to the input size (torch.Size([1241, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1133, 2])) that is different to the input size (torch.Size([1133, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1214, 2])) that is different to the input size (torch.Size([1214, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1050, 2])) that is different to the input size (torch.Size([1050, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1055, 2])) that is different to the input size (torch.Size([1055, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1278, 2])) that is different to the input size (torch.Size([1278, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1098, 2])) that is different to the input size (torch.Size([1098, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1078, 2])) that is different to the input size (torch.Size([1078, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1067, 2])) that is different to the input size (torch.Size([1067, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1160, 2])) that is different to the input size (torch.Size([1160, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1242, 2])) that is different to the input size (torch.Size([1242, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1016, 2])) that is different to the input size (torch.Size([1016, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1116, 2])) that is different to the input size (torch.Size([1116, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1149, 2])) that is different to the input size (torch.Size([1149, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1175, 2])) that is different to the input size (torch.Size([1175, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1010, 2])) that is different to the input size (torch.Size([1010, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1232, 2])) that is different to the input size (torch.Size([1232, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1201, 2])) that is different to the input size (torch.Size([1201, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1223, 2])) that is different to the input size (torch.Size([1223, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1135, 2])) that is different to the input size (torch.Size([1135, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1123, 2])) that is different to the input size (torch.Size([1123, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Current batch: 600\n","Average train loss of recent 1 batches: 1185159726.72\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1280, 2])) that is different to the input size (torch.Size([1280, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1164, 2])) that is different to the input size (torch.Size([1164, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1275, 2])) that is different to the input size (torch.Size([1275, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1172, 2])) that is different to the input size (torch.Size([1172, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1290, 2])) that is different to the input size (torch.Size([1290, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1251, 2])) that is different to the input size (torch.Size([1251, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1158, 2])) that is different to the input size (torch.Size([1158, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1216, 2])) that is different to the input size (torch.Size([1216, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1276, 2])) that is different to the input size (torch.Size([1276, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1026, 2])) that is different to the input size (torch.Size([1026, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1197, 2])) that is different to the input size (torch.Size([1197, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1264, 2])) that is different to the input size (torch.Size([1264, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1003, 2])) that is different to the input size (torch.Size([1003, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1146, 2])) that is different to the input size (torch.Size([1146, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1062, 2])) that is different to the input size (torch.Size([1062, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1156, 2])) that is different to the input size (torch.Size([1156, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1117, 2])) that is different to the input size (torch.Size([1117, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1271, 2])) that is different to the input size (torch.Size([1271, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1151, 2])) that is different to the input size (torch.Size([1151, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1130, 2])) that is different to the input size (torch.Size([1130, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1189, 2])) that is different to the input size (torch.Size([1189, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Current batch: 800\n","Average train loss of recent 1 batches: 1120914686.4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1131, 2])) that is different to the input size (torch.Size([1131, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1045, 2])) that is different to the input size (torch.Size([1045, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1084, 2])) that is different to the input size (torch.Size([1084, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1293, 2])) that is different to the input size (torch.Size([1293, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1033, 2])) that is different to the input size (torch.Size([1033, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1210, 2])) that is different to the input size (torch.Size([1210, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Current batch: 1000\n","Average train loss of recent 1 batches: 1083651272.8\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1297, 2])) that is different to the input size (torch.Size([1297, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1086, 2])) that is different to the input size (torch.Size([1086, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1085, 2])) that is different to the input size (torch.Size([1085, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1163, 2])) that is different to the input size (torch.Size([1163, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1140, 2])) that is different to the input size (torch.Size([1140, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1142, 2])) that is different to the input size (torch.Size([1142, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1103, 2])) that is different to the input size (torch.Size([1103, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Current batch: 1200\n","Average train loss of recent 1 batches: 1065212262.56\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1268, 2])) that is different to the input size (torch.Size([1268, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Current batch: 1400\n","Average train loss of recent 1 batches: 1107138923.2\n","Total train loss: 1353900090.24\n","\n","[ Test epoch: 1 ]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 1107, 2])) that is different to the input size (torch.Size([1107, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["Test average loss: 1363284127.2533333\n","\n","[ Train epoch: 2 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 1000312115.36\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 1066594549.28\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 1061428905.92\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 1056143276.64\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 1034874842.08\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 1029800484.48\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 1075653543.36\n","Total train loss: 1049499650.9653333\n","\n","[ Test epoch: 2 ]\n","Test average loss: 1339153341.0133333\n","\n","[ Train epoch: 3 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 975339777.44\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 1041741267.36\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 1039591564.16\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 1036484097.28\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 1015946964.48\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 1005860513.92\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 1052716906.4\n","Total train loss: 1026574551.7013333\n","\n","[ Test epoch: 3 ]\n","Test average loss: 1298303877.8666666\n","\n","[ Train epoch: 4 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 951538143.68\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 1016958777.28\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 1014126013.28\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 1008407539.04\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 991988008.16\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 978913425.12\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 1020609556.64\n","Total train loss: 1000244558.5066667\n","\n","[ Test epoch: 4 ]\n","Test average loss: 1254462951.2533333\n","\n","[ Train epoch: 5 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 926974346.56\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 991255807.36\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 990727875.2\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 979926295.84\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 958772559.84\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 950548391.84\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 1002671759.52\n","Total train loss: 973722814.6773334\n","\n","[ Test epoch: 5 ]\n","Test average loss: 1213444394.7733333\n","\n","[ Train epoch: 6 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 890260174.88\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 953023147.84\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 931627322.08\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 906877600.8\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 867151494.56\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 821671517.92\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 808413830.08\n","Total train loss: 871960214.7306666\n","\n","[ Test epoch: 6 ]\n","Test average loss: 904028621.9733334\n","\n","[ Train epoch: 7 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 638360793.04\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 666371963.2\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 673612476.0\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 652894124.96\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 631687591.6\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 624851722.48\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 666174306.96\n","Total train loss: 651493919.4026667\n","\n","[ Test epoch: 7 ]\n","Test average loss: 854316128.3733333\n","\n","[ Train epoch: 8 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 587485100.64\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 634551289.52\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 636010919.52\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 628883110.8\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 604559919.6\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 611813302.88\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 654370580.24\n","Total train loss: 624611273.2266667\n","\n","[ Test epoch: 8 ]\n","Test average loss: 860433152.16\n","\n","[ Train epoch: 9 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 574841159.12\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 627305884.64\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 628259899.36\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 620387440.48\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 602306994.32\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 595785834.8\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 660572651.2\n","Total train loss: 617314523.1466666\n","\n","[ Test epoch: 9 ]\n","Test average loss: 820884874.6666666\n","\n","[ Train epoch: 10 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 573149430.48\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 625252885.68\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 618192684.48\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 618196431.92\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 600873352.64\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 598539944.56\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 641691738.08\n","Total train loss: 612704467.4666667\n","\n","[ Test epoch: 10 ]\n","Test average loss: 800682571.04\n","\n","[ Train epoch: 11 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 562220745.52\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 608011257.28\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 617844903.84\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 607946723.28\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 597987685.04\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 592722088.64\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 640465316.48\n","Total train loss: 605899090.9333333\n","\n","[ Test epoch: 11 ]\n","Test average loss: 827218259.7866666\n","\n","[ Train epoch: 12 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 556149651.28\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 611616054.64\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 614439754.8\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 605603468.96\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 595733089.52\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 588016332.48\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 635619653.12\n","Total train loss: 603473655.1146667\n","\n","[ Test epoch: 12 ]\n","Test average loss: 804659767.7866666\n","\n","[ Train epoch: 13 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 554383551.84\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 600364258.8\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 606459441.68\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 605525938.88\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 583069226.24\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 588912650.0\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 638780593.76\n","Total train loss: 598933787.744\n","\n","[ Test epoch: 13 ]\n","Test average loss: 766386029.4933333\n","\n","[ Train epoch: 14 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 553544924.56\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 608070353.12\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 604360192.96\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 603767545.76\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 583009968.32\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 586197556.64\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 635890536.56\n","Total train loss: 598070651.52\n","\n","[ Test epoch: 14 ]\n","Test average loss: 787357708.2666667\n","\n","[ Train epoch: 15 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 546539536.0\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 602103634.8\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 599691394.56\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 596529871.36\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 579499077.6\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 585637770.48\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 627324131.6\n","Total train loss: 593459229.8133334\n","\n","[ Test epoch: 15 ]\n","Test average loss: 809174932.16\n","\n","[ Train epoch: 16 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 543307036.96\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 607330847.12\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 601941095.36\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 595884481.84\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 575949176.16\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 583889674.64\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 623502632.16\n","Total train loss: 592572773.92\n","\n","[ Test epoch: 16 ]\n","Test average loss: 776676233.28\n","\n","[ Train epoch: 17 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 542082791.92\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 611092420.32\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 600427496.48\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 593581999.36\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 574962769.84\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 579032690.16\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 629365648.32\n","Total train loss: 592493192.928\n","\n","[ Test epoch: 17 ]\n","Test average loss: 790746868.5333333\n","\n","[ Train epoch: 18 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 548226836.64\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 597018212.88\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 595703921.92\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 594388360.88\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 578481380.48\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 580978206.96\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 627595011.68\n","Total train loss: 590804750.7946666\n","\n","[ Test epoch: 18 ]\n","Test average loss: 784640907.36\n","\n","[ Train epoch: 19 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 547289960.64\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 597162551.28\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 594345406.96\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 591936078.88\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 576150966.32\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 580594542.64\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 621822866.0\n","Total train loss: 588805841.3333334\n","\n","[ Test epoch: 19 ]\n","Test average loss: 780982801.6\n","\n","[ Train epoch: 20 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 543367966.72\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 594065705.04\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 592923345.12\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 588320315.76\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 574352243.6\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 574375401.04\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 623402131.84\n","Total train loss: 586562360.992\n","\n","[ Test epoch: 20 ]\n","Test average loss: 776824610.1866666\n","\n","[ Train epoch: 21 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 539674148.96\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 593900523.92\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 597701313.76\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 581824020.56\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 575923655.04\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 573308693.28\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 621969045.92\n","Total train loss: 585337326.816\n","\n","[ Test epoch: 21 ]\n","Test average loss: 768964863.8933333\n","\n","[ Train epoch: 22 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 539814995.04\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 594455048.64\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 590211253.84\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 582565848.56\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 572248920.56\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 569210450.72\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 618779749.44\n","Total train loss: 583165875.7973334\n","\n","[ Test epoch: 22 ]\n","Test average loss: 779217746.9333333\n","\n","[ Train epoch: 23 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 538092548.0\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 592735890.24\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 586977462.48\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 584230165.68\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 565399750.56\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 570998232.0\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 620102365.28\n","Total train loss: 581876929.76\n","\n","[ Test epoch: 23 ]\n","Test average loss: 781559243.68\n","\n","[ Train epoch: 24 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 540231442.96\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 594345417.28\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 587469855.36\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 588245941.44\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 571293268.8\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 571440176.88\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 616333351.68\n","Total train loss: 583385235.456\n","\n","[ Test epoch: 24 ]\n","Test average loss: 769495922.88\n","\n","[ Train epoch: 25 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 540293934.4\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 589864850.4\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 591213823.28\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 583928409.28\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 570377340.32\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 573443262.16\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 617495099.84\n","Total train loss: 583754851.264\n","\n","[ Test epoch: 25 ]\n","Test average loss: 769224004.6933334\n","\n","[ Train epoch: 26 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 532501704.0\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 587845986.24\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 583839204.08\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 589456719.76\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 568883008.16\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 571519597.84\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 615116739.68\n","Total train loss: 580658725.376\n","\n","[ Test epoch: 26 ]\n","Test average loss: 777223892.5333333\n","\n","[ Train epoch: 27 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 539110443.68\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 584203412.48\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 590906228.24\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 585953880.32\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 571386316.64\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 570618495.12\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 614785338.08\n","Total train loss: 582151305.5573334\n","\n","[ Test epoch: 27 ]\n","Test average loss: 769570373.8666667\n","\n","[ Train epoch: 28 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 533010121.68\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 588521422.08\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 590785214.4\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 592292484.0\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 564973436.56\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 573180525.28\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 621566767.76\n","Total train loss: 582758089.6533333\n","\n","[ Test epoch: 28 ]\n","Test average loss: 764098936.2666667\n","\n","[ Train epoch: 29 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 540093863.84\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 582833716.08\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 582082427.12\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 582298527.44\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 568220350.48\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 575791156.8\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 617681278.56\n","Total train loss: 581393821.632\n","\n","[ Test epoch: 29 ]\n","Test average loss: 764701588.3733333\n","\n","[ Train epoch: 30 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 532190640.4\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 584282671.04\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 585745896.24\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 581309351.12\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 570270664.48\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 573034813.68\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 612348887.2\n","Total train loss: 579386534.3253334\n","\n","[ Test epoch: 30 ]\n","Test average loss: 787404967.9466667\n","\n","[ Train epoch: 31 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 534387649.68\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 590869347.84\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 589076676.4\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 579763814.24\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 567415350.72\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 570286216.96\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 619364192.16\n","Total train loss: 580973516.1386666\n","\n","[ Test epoch: 31 ]\n","Test average loss: 782481164.9066666\n","\n","[ Train epoch: 32 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 536349972.08\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 594805620.56\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 588351138.08\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 590058319.44\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 561726336.96\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 566989324.88\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 617503945.04\n","Total train loss: 581420084.4373333\n","\n","[ Test epoch: 32 ]\n","Test average loss: 758599447.7866666\n","\n","[ Train epoch: 33 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 538776574.0\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 592088203.28\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 587411802.64\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 582111379.52\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 567196780.72\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 572146963.28\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 618064022.56\n","Total train loss: 581598987.7226666\n","\n","[ Test epoch: 33 ]\n","Test average loss: 772413160.9066666\n","\n","[ Train epoch: 34 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 540458058.8\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 583484077.12\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 584031880.8\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 578171523.68\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 566445004.88\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 568311920.48\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 620230265.68\n","Total train loss: 579427632.0213333\n","\n","[ Test epoch: 34 ]\n","Test average loss: 771665728.3733333\n","\n","[ Train epoch: 35 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 534772812.32\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 583684163.68\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 584780261.04\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 582267252.24\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 566383412.16\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 566579411.92\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 617488120.8\n","Total train loss: 578594983.9893334\n","\n","[ Test epoch: 35 ]\n","Test average loss: 765503361.6\n","\n","[ Train epoch: 36 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 532157858.56\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 584085941.92\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 581097741.52\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 581747623.2\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 562979755.28\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 570395424.72\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 616850327.28\n","Total train loss: 577830400.9066666\n","\n","[ Test epoch: 36 ]\n","Test average loss: 765306531.04\n","\n","[ Train epoch: 37 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 536626621.12\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 584018716.48\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 581863247.28\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 577304508.56\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 566673166.0\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 567098191.84\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 615261414.48\n","Total train loss: 577601269.3866667\n","\n","[ Test epoch: 37 ]\n","Test average loss: 760500049.92\n","\n","[ Train epoch: 38 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 535842412.72\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 591338322.24\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 583992269.6\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 584618298.64\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 570582503.6\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 565329290.56\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 618538231.36\n","Total train loss: 580646219.0826666\n","\n","[ Test epoch: 38 ]\n","Test average loss: 769121186.3466667\n","\n","[ Train epoch: 39 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 530625157.52\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 591959637.84\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 590252687.84\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 577584649.76\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 562836013.68\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 569489183.68\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 614971171.36\n","Total train loss: 579324994.112\n","\n","[ Test epoch: 39 ]\n","Test average loss: 772487821.0666667\n","\n","[ Train epoch: 40 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 540284134.08\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 581809350.0\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 586029329.84\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 582443886.8\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 563621801.2\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 567344835.76\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 613602805.28\n","Total train loss: 578504368.9066666\n","\n","[ Test epoch: 40 ]\n","Test average loss: 765567495.7866666\n","\n","[ Train epoch: 41 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 535606478.56\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 589030900.0\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 583582905.84\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 575376917.68\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 566644946.96\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 566785211.28\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 612536597.12\n","Total train loss: 577964665.216\n","\n","[ Test epoch: 41 ]\n","Test average loss: 765803186.4\n","\n","[ Train epoch: 42 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 532391509.6\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 585270008.0\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 588444266.24\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 584601558.96\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 566166817.92\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 568866046.16\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 612672044.88\n","Total train loss: 579013395.84\n","\n","[ Test epoch: 42 ]\n","Test average loss: 754589812.8\n","\n","[ Train epoch: 43 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 536425628.88\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 589882221.36\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 587660703.28\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 581937794.96\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 563406837.36\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 568109620.08\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 613772936.72\n","Total train loss: 579254835.6693333\n","\n","[ Test epoch: 43 ]\n","Test average loss: 776949436.0533333\n","\n","[ Train epoch: 44 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 534494846.08\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 585012712.32\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 584357326.8\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 577072699.36\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 556466713.6\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 565284838.24\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 610409120.32\n","Total train loss: 575448597.7813333\n","\n","[ Test epoch: 44 ]\n","Test average loss: 771592747.4666667\n","\n","[ Train epoch: 45 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 536334146.48\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 584386834.0\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 586584161.68\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 585226313.12\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 569900771.68\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 571735067.6\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 614530064.88\n","Total train loss: 580423077.2266667\n","\n","[ Test epoch: 45 ]\n","Test average loss: 756702977.28\n","\n","[ Train epoch: 46 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 530833637.84\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 586558786.32\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 584708962.32\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 576733166.96\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 557381803.04\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 568531226.48\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 612866254.96\n","Total train loss: 576039390.6453333\n","\n","[ Test epoch: 46 ]\n","Test average loss: 777206143.68\n","\n","[ Train epoch: 47 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 532757045.68\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 582933692.56\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 587137916.56\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 585893100.16\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 559978145.84\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 568636052.24\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 611044229.04\n","Total train loss: 577576282.4853333\n","\n","[ Test epoch: 47 ]\n","Test average loss: 767549809.12\n","\n","[ Train epoch: 48 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 531767739.28\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 586774268.96\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 586804731.6\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 580142728.64\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 563492231.68\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 567965110.16\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 615644669.2\n","Total train loss: 578015510.272\n","\n","[ Test epoch: 48 ]\n","Test average loss: 758222363.0933334\n","\n","[ Train epoch: 49 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 530580741.28\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 592142789.44\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 580255626.4\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 579522735.52\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 559901809.76\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 558835695.36\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 612348488.96\n","Total train loss: 575680962.4106667\n","\n","[ Test epoch: 49 ]\n","Test average loss: 748696738.6133333\n","\n","[ Train epoch: 50 ]\n","\n","Current batch: 200\n","Average train loss of recent 1 batches: 533176447.28\n","\n","Current batch: 400\n","Average train loss of recent 1 batches: 586121342.32\n","\n","Current batch: 600\n","Average train loss of recent 1 batches: 583094499.12\n","\n","Current batch: 800\n","Average train loss of recent 1 batches: 581549473.84\n","\n","Current batch: 1000\n","Average train loss of recent 1 batches: 562323847.52\n","\n","Current batch: 1200\n","Average train loss of recent 1 batches: 568178691.76\n","\n","Current batch: 1400\n","Average train loss of recent 1 batches: 613184306.72\n","Total train loss: 576975474.208\n","\n","[ Test epoch: 50 ]\n","Test average loss: 776861502.3466667\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt"],"metadata":{"id":"_en_ULaUy8nD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loss_all_area = np.sqrt(np.array(seq_train_loss))\n","test_loss_all_area = np.sqrt(np.array(seq_test_loss))"],"metadata":{"id":"xQ1LY1RI6tIt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# With all area\n","plt.title('GCN Loss')\n","plt.plot(train_loss_all_area,color='darkred',label='Train Loss')\n","plt.plot(test_loss_all_area,color='darkblue',label='Test Loss')\n","plt.legend()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"pjGXKjK26q7N","executionInfo":{"status":"ok","timestamp":1665036734775,"user_tz":-540,"elapsed":637,"user":{"displayName":"namhun kim","userId":"12332195563700468765"}},"outputId":"9a4de649-656d-4bfc-c106-d41032a7e51b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7fbc3f8a3610>"]},"metadata":{},"execution_count":63},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["train_loss_gs = np.sqrt(np.array(seq_train_loss))\n","test_loss_gs = np.sqrt(np.array(seq_test_loss))"],"metadata":{"id":"60nC8yHI63-3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# With Gangnam and Seocho\n","plt.title('GCN Loss')\n","plt.plot(train_loss_gs,color='darkred',label='Train Loss')\n","plt.plot(test_loss_gs,color='darkblue',label='Test Loss')\n","plt.legend()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"dFtp9s6f_QnR","executionInfo":{"status":"ok","timestamp":1665037880356,"user_tz":-540,"elapsed":4,"user":{"displayName":"namhun kim","userId":"12332195563700468765"}},"outputId":"e9072fbb-3650-4e75-cdeb-34e8f6bcf884"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7fbc03788bd0>"]},"metadata":{},"execution_count":86},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV9b3/8dcnJ/tCQhaWJECQHQIEiWyKItQFUFGq1q1gq9drq6LXXdtbe7Ve66+uqHWpRbS1AlJZXBFFES9rQGSRfU0gkIXs+0k+vz/OJAbZQkhyIOfzfDzmMXO+850538GYd+Y7M98RVcUYY4xv8/N2A4wxxnifhYExxhgLA2OMMRYGxhhjsDAwxhiDhYExxhgsDIwxxmBhYHyIiFwnIitEpEREspzl34qI1KszREQ+EZF8ETkkIitF5FfOulEioiLy15/s91sRufkY3/lHEflnsx6YMU3AwsD4BBG5D3gR+AvQAWgP3A6cCwQ6dYYDi4DFQHcgBvgNMLberkqAX4pIUgs13ZgWYWFgWj0RiQQeB36rqrNVtUg9vlPVG1W1wqn6F+BtVX1aVXOcOqtV9dp6u8sHpgOPNUG7rhCRjc5ZyNci0qfeuodEZJ+IFInIFhEZ45QPEZE0ESkUkYMi8typtsMYsDAwvmE4EATMO1YFEQl16s1uwP6eBH4uIr0a2yAR6Qm8B9wDxAGfAB+KSKCz3zuBc1Q1ArgE2O1s+iLwoqq2AboBsxrbBmPqszAwviAWyFFVd22BiCx1/iIvE5HzgbZ4/n/IPNHOVPUA8Bqes43G+gXwsaouVNUq4BkgBBgBVOMJr74iEqCqu1V1h7NdFdBdRGJVtVhVl59CG4ypY2FgfEEuECsi/rUFqjpCVaOcdX5AHlADdGzgPp8GLhGRgY1sUzywp157aoB0IEFVt+M5Y/gjkCUiM0Qk3ql6C9AT2Cwiq0TkskZ+vzGHsTAwvmAZUAFMOFYFVS116v28ITtU1VzgBeCJRrZpP9Cl9oNzR1MnYJ+z/3+p6nlOHcUTPqjqNlW9HmjnlM0WkbBGtsGYOhYGptVT1Xzgf4C/isjVIhIhIn4ikgLU/0X6IHCziDwgIjEAIjJQRGYcY9fP4enW6XOM9bX8RCS43hSEp69/vIiMEZEA4D48gbVURHqJyGinXjlQhuesBRG5SUTinDOJfGf/NSf5T2LMESwMjE9Q1f8H3IvnF/5BZ3odeAhY6tRZCox2pp0icgh4A8/F3aPtsxD4f0D0Cb7+ejy/0GunHaq6BbgJeAnIAS4HLlfVSjzXC/7slB/AcxbwiLOvS4GNIlKM52LydapadjL/FsYcjdjLbYwxxtiZgTHGGAsDY4wxFgbGGGOwMDDGGAP4n7jK6Sk2NlaTkpK83QxjjDljrF69OkdV44627owNg6SkJNLS0rzdDGOMOWOIyJ5jrbNuImOMMRYGxhhjLAyMMcZwBl8zMMa0HlVVVWRkZFBeXu7tprQKwcHBJCYmEhAQ0OBtLAyMMV6XkZFBREQESUlJ1HsltWkEVSU3N5eMjAy6du3a4O2sm8gY43Xl5eXExMRYEDQBESEmJuakz7IsDIwxpwULgqbTmH9LnwuDZU88wa4FC7zdDGOMOa34XBis+stf2P3ZZ95uhjHmNJKbm0tKSgopKSl06NCBhISEus+VlZXH3TYtLY0pU6ac1PclJSWRk5NzKk1ucj53ATkoMpKKggJvN8MYcxqJiYlh7dq1APzxj38kPDyc+++/v2692+3G3//ovy5TU1NJTU1tkXY2J587Mwi0MDDGNMDNN9/M7bffztChQ3nwwQdZuXIlw4cPZ9CgQYwYMYItW7YA8PXXX3PZZZcBniD59a9/zahRozjrrLOYOnVqg79v9+7djB49mgEDBjBmzBj27t0LwPvvv09ycjIDBw7k/PPPB2Djxo0MGTKElJQUBgwYwLZt2075eO3MwBhzWll0zz1kOX+lN5V2KSmMfuGFk94uIyODpUuX4nK5KCwsZMmSJfj7+/PFF1/w6KOP8u9///uIbTZv3sxXX31FUVERvXr14je/+U2D7ve/6667mDx5MpMnT2batGlMmTKFuXPn8vjjj7NgwQISEhLIz/e89vq1117j7rvv5sYbb6SyspLq6uqTPraf8skwKM3K8nYzjDFngGuuuQaXywVAQUEBkydPZtu2bYgIVVVVR91m/PjxBAUFERQURLt27Th48CCJiYkn/K5ly5bxwQcfAPDLX/6SBx98EIBzzz2Xm2++mWuvvZaJEycCMHz4cJ588kkyMjKYOHEiPXr0OOVj9b0wiIoirwlOqYwxzaMxf8E3l7CwsLrl//7v/+bCCy9kzpw57N69m1GjRh11m6CgoLpll8uF2+0+pTa89tprrFixgo8//pjBgwezevVqbrjhBoYOHcrHH3/MuHHjeP311xk9evQpfY/PXTOwbiJjTGMUFBSQkJAAwPTp05t8/yNGjGDGjBkAvPvuu4wcORKAHTt2MHToUB5//HHi4uJIT09n586dnHXWWUyZMoUJEyawbt26U/5+nwyDSgsDY8xJevDBB3nkkUcYNGjQKf+1DzBgwAASExNJTEzk3nvv5aWXXuKtt95iwIAB/OMf/+DFF18E4IEHHqB///4kJyczYsQIBg4cyKxZs0hOTiYlJYUNGzYwadKkU26PqOop78QbUlNTtTEvt1nx1FMsefRR7ikrwz84uBlaZow5WZs2baJPnz7ebkarcrR/UxFZrapHvQ/2hGcGItJLRNbWmwpF5B4RiRaRhSKyzZm3deqLiEwVke0isk5Ezq63r8lO/W0iMrle+WARWe9sM1Wa8bn0wMhIAOsqMsaYek4YBqq6RVVTVDUFGAyUAnOAh4EvVbUH8KXzGWAs0MOZbgNeBRCRaOAxYCgwBHisNkCcOv9Rb7tLm+TojiKoNgycW7SMMcac/DWDMcAOVd0DTADedsrfBq50licA76jHciBKRDoClwALVfWQquYBC4FLnXVtVHW5evqs3qm3ryYXFBUF2JmBMcbUd7JhcB3wnrPcXlUzneUDQHtnOQFIr7dNhlN2vPKMo5QfQURuE5E0EUnLzs4+yaZ7BFk3kTHGHKHBYSAigcAVwPs/Xef8Rd/sV6JV9Q1VTVXV1Li4uEbtw8LAGGOOdDJnBmOBNap60Pl80OniwZnXPta7D+hUb7tEp+x45YlHKW8WtWFgt5caY8yPTiYMrufHLiKA+UDtHUGTgXn1yic5dxUNAwqc7qQFwMUi0ta5cHwxsMBZVygiw5y7iCbV21eTszMDY8xPncoQ1uAZrG7p0qVHXTd9+nTuvPPOpm5yk2vQcBQiEgZcBPxnveI/A7NE5BZgD3CtU/4JMA7YjufOo18BqOohEXkCWOXUe1xVDznLvwWmAyHAp87ULAIjIkCEcrubyBjjONEQ1ify9ddfEx4ezogRI5qric2uQWcGqlqiqjGqWlCvLFdVx6hqD1X9We0vducuojtUtZuq9lfVtHrbTFPV7s70Vr3yNFVNdra5U5vxSTjx8yOoTRvrJjLGHNfq1au54IILGDx4MJdccgmZmZ77ZaZOnUrfvn0ZMGAA1113Hbt37+a1117j+eefJyUlhSVLljRo/8899xzJyckkJyfzgjMeU0lJCePHj2fgwIEkJyczc+ZMAB5++OG67zyZkDoZPjdQHdg7DYw5nd1zzyLWrm3akYVTUtrxwgsNH8hNVbnrrruYN28ecXFxzJw5k9/97ndMmzaNP//5z+zatYugoCDy8/OJiori9ttvP6mzidWrV/PWW2+xYsUKVJWhQ4dywQUXsHPnTuLj4/n4448Bz3hIubm5zJkzh82bNyMidcNYNzWfG5sIbLA6Y8zxVVRUsGHDBi666CJSUlL405/+REaG5w74AQMGcOONN/LPf/7zmG8/O5Fvv/2Wq666irCwMMLDw5k4cSJLliyhf//+LFy4kIceeoglS5YQGRlJZGQkwcHB3HLLLXzwwQeEhoY25aHW8ckzAwsDY05fJ/MXfHNRVfr168eyZcuOWPfxxx/zzTff8OGHH/Lkk0+yfv36Jvvenj17smbNGj755BN+//vfM2bMGP7whz+wcuVKvvzyS2bPns3LL7/MokWLmuw7a/nsmYFdMzDGHEtQUBDZ2dl1YVBVVcXGjRupqakhPT2dCy+8kKeffpqCggKKi4uJiIigqKiowfsfOXIkc+fOpbS0lJKSEubMmcPIkSPZv38/oaGh3HTTTTzwwAOsWbOG4uJiCgoKGDduHM8//zzff/99sxyzz54Z5G7a5O1mGGNOU35+fsyePZspU6ZQUFCA2+3mnnvuoWfPntx0000UFBSgqkyZMoWoqCguv/xyrr76aubNm8dLL71U9y6CWtOnT2fu3Ll1n5cvX87NN9/MkCFDALj11lsZNGgQCxYs4IEHHsDPz4+AgABeffVVioqKmDBhAuXl5agqzz33XLMcs88NYQ3wxR13sGXmTO7IyWniVhljGsOGsG56TT6EdWtUe83gTA1CY4xpaj4ZBoGRkdS43bjLyrzdFGOMOS34ZBjYkBTGnH7sTL3pNObf0sLAGON1wcHB5ObmWiA0AVUlNzeX4JN8ra/P3k0E9rYzY04XiYmJZGRk0Nj3lJjDBQcHk5iYeOKK9fhmGNjbzow5rQQEBNC1a1dvN8OnWTeRMcYY3w4DewrZGGM8fDoM7MzAGGM8fDIMAsLDET8/CwNjjHH4ZBiICIFt2tjdRMYY4/DJMADPHUV2ZmCMMR6+Gwb2TgNjjKljYWCMMca3w8BuLTXGGA+fDoNyu4BsjDGAD4dBoJ0ZGGNMHZ8Ng+CoKCoKC22URGOMwYfDIDAyEq2upqqkxNtNMcYYr/PZMLAhKYwx5kcWBhYGxhhjYWBDUhhjjIWBnRkYYwy+HAbO287s9lJjjPHlMLAzA2OMqeOzYRBoYWCMMXV8NgwCQkMRl8vCwBhj8OEwEBHPyKV2N5ExxvhuGIANY22MMbV8OwzsbWfGGAP4ehjYyKXGGANYGNiZgTHG0MAwEJEoEZktIptFZJOIDBeRaBFZKCLbnHlbp66IyFQR2S4i60Tk7Hr7mezU3yYik+uVDxaR9c42U0VEmv5QjxRoYWCMMUDDzwxeBD5T1d7AQGAT8DDwpar2AL50PgOMBXo4023AqwAiEg08BgwFhgCP1QaIU+c/6m136akdVsPY3UTGGONxwjAQkUjgfODvAKpaqar5wATgbafa28CVzvIE4B31WA5EiUhH4BJgoaoeUtU8YCFwqbOujaouV8+bZt6pt69mFVT7gpuampb4OmOMOW015MygK5ANvCUi34nImyISBrRX1UynzgGgvbOcAKTX2z7DKTteecZRyo8gIreJSJqIpGVnZzeg6ccXFBkJqlQWF5/yvowx5kzWkDDwB84GXlXVQUAJP3YJAeD8Rd/s749U1TdUNVVVU+Pi4k55fzY+kTHGeDQkDDKADFVd4XyejSccDjpdPDjzLGf9PqBTve0TnbLjlScepbzZWRgYY4zHCcNAVQ8A6SLSyykaA/wAzAdq7wiaDMxzlucDk5y7ioYBBU530gLgYhFp61w4vhhY4KwrFJFhzl1Ek+rtq1nVhoE9a2CM8XX+Dax3F/CuiAQCO4Ff4QmSWSJyC7AHuNap+wkwDtgOlDp1UdVDIvIEsMqp97iqHnKWfwtMB0KAT52p2dWGQbndUWSM8XENCgNVXQukHmXVmKPUVeCOY+xnGjDtKOVpQHJD2tKU7AU3xhjj4fNPIINdMzDGGJ8OA3vBjTHGePh0GPgHB+MXEGBhYIzxeT4dBnUvuLEwMMb4OJ8OA7DxiYwxBiwM7AU3xhiDhYG94MYYY7AwsGsGxhiDhYG94MYYY7AwsDMDY4zBwsBzzaCwkJrqam83xRhjvMbCoHZ8oqIiL7fEGGO8x8LAhqQwxhgLA3ungTHGWBjYmYExxmBhYCOXGmMMFgY/nhnY+ETGGB9mYeDcTWRnBsYYX2ZhYN1ExhhjYeAfFIQrKMjCwBjj03w+DMBGLjXGGAsDPGFQbheQjTE+zMIAG7nUGGMsDIDgqCjrJjLG+DQLA+zMwBhjLAywdxoYY4yFARYGxhhjYYAnDKqKi6lxu73dFGOM8QoLA+o9hVxY6OWWGGOMd1gYYOMTGWOMhQH2ghtjjLEwwAarM8YYCwPsBTfGGGNhgL3gxhhjLAywbiJjjLEwwMLAGGMsDABXYCD+ISEWBsYYn9WgMBCR3SKyXkTWikiaUxYtIgtFZJszb+uUi4hMFZHtIrJORM6ut5/JTv1tIjK5XvlgZ//bnW2lqQ/0ROwFN8YYX3YyZwYXqmqKqqY6nx8GvlTVHsCXzmeAsUAPZ7oNeBU84QE8BgwFhgCP1QaIU+c/6m13aaOPqJFsfCJjjC87lW6iCcDbzvLbwJX1yt9Rj+VAlIh0BC4BFqrqIVXNAxYClzrr2qjqclVV4J16+2oxgZGRdjeRMcZnNTQMFPhcRFaLyG1OWXtVzXSWDwDtneUEIL3ethlO2fHKM45SfgQRuU1E0kQkLTs7u4FNb5iYvn3Zt3Spvf7SGOOTGhoG56nq2Xi6gO4QkfPrr3T+otembtxPqeobqpqqqqlxcXFNuu+zp0yhqriYdW+80aT7NcaYM0GDwkBV9znzLGAOnj7/g04XD848y6m+D+hUb/NEp+x45YlHKW9R7QcNovOYMax58UWqKytb+uuNMcarThgGIhImIhG1y8DFwAZgPlB7R9BkYJ6zPB+Y5NxVNAwocLqTFgAXi0hb58LxxcACZ12hiAxz7iKaVG9fLeqc+++neP9+Ns+Y4Y2vN8YYr2nImUF74FsR+R5YCXysqp8BfwYuEpFtwM+czwCfADuB7cDfgN8CqOoh4AlglTM97pTh1HnT2WYH8OmpH9rJS7rkEmKTk1n1zDN4er6MMcY3yJn6Sy81NVXT0tKafL8bpk/ns1/9iqsXLCDp4oubfP/GGOMtIrK63uMBh7EnkH+i9/XXE9ahA2nPPuvtphhjTIuxMPgJ/6Agzp4yhd2ff072unXebo4xxrQIC4OjGPCf/0lAWBir7OzAGOMjfCoMKiurmTlzM6tWZR63Xkh0NP1vuYXN//oXRRkZx61rjDGtgU+FAcDtty/k5Ze/O2G9s++5B62pYc1LL7VAq4wxxrt8KgwCA11cdVUP5s7dTkWF+7h1o7p2pefVV/P9a69RUVjYQi00xhjv8KkwALjmmp4UFlby+ed7Tlg39f77qSwsZP3f/94CLTPGGO/xuTAYM6YLbdsG8/77W05Yt+M555B4/vmkPfMMpU08MJ4xxpxOfC4MPF1F3Zk3bzvl5cfvKgK44JlnKD90iDmXX05VaWkLtNAYY1qez4UBwDXX9HK6inafsG7Hc85h/HvvkblyJR/fcAM11dXN30BjjGlhPhkGY8Z0drqKtjaofo8rr2T01KlsnzePRVOm2LhFxphWx9/bDfCGgAAXEyf2YNasLZSXuwkOPvE/w9l33knhnj2kPfMMbbp0YciDD7ZAS40xpmX45JkBeO4qKiqqZMGC3Q3e5oKnn6bXL37BNw89xKb33mu+xhljTAvz2TAYPboz0dENu6uolvj5Mfbtt0k8/3w+nTyZvV9/3XwNNMaYFuSzYVDbVTR//o4G3VVUyz8oiCvnziWqe3fmXXklRfta/KVsxhjT5Hw2DMBzV9HJdhUBBLdty1Xz51NZXGxDXRtjWgWfDoMLL+xETEwIs2Y1vKuoVtvu3elz/fWse+MNynJzm6F1xhjTcnw6DH7sKtpOWVnVSW8/5OGHqSop4buXX26G1hljTMvx6TAAz11FxcVVJ91VBBDbrx/drriCNVOnUllc3PSNM8aYFuLzYXDhhZ0b3VUEMPThhyk/dIh1f/tbE7fMGGNajs+Hgb+/X91dRY3pKoofPpzECy4g7dlncVdUNEMLjTGm+fl8GABce20vSkqq+Oyz3Y3afugjj1C8bx+b/vnPpm2YMca0EAsDYNSoTsTGhvDyy9+d1DMHtZIuvph2gwax8umnbSA7Y8wZycIAT1fRH/84gkWL9jJmzCyyskpOansRYegjj5C3bRvb5sxpplYaY0zzsTBw3HHHIGbNupw1a7IYOvRdNm7MOante0ycSNuePVn51FM2qqkx5oxjYVDPNdf0YvHiX1BW5mbEiH+xYMGuBm/r53Ix5MEHObhmDXsWLmzGVhpjTNOzMPiJIUM6snLlTSQlRTJu3Ae88sp3Dd62z003EZ6QwIqnnmrGFhpjTNOzMDiKzp3b8O231zN+/FnceeeX3HHHFw26sOwfFETqvfeS/vXX7F++vAVaaowxTcPC4BgiIgKZM2cC992Xyl//upZzzvkna9dmnXC7AbfdRkB4OOvffLMFWmmMMU3DwuA4XC4/nnlmFJ98MpGcnDKGDPkn//u/y3G7a465TWB4OD2vvpots2ZRVVbWgq01xpjGszBogLFjz2LDhpu58sru/O5333L++TPYvj3vmPX7TZpEZVERO+bNa8FWGmNM41kYNFBMTAgzZ17Ou++OZ9OmXAYOfJvXX//+qHU7XXABEZ06sfGdd1q4lcYY0zgWBidBRLjhhj6sX38zI0YkcPvtC5k3b/uR9fz86PvLX7J7wQKKMzO90FJjjDk5FgaNkJgYwaef/pw+faJ54IHFVFYeOQRF31/+Eq2pYdO//uWFFhpjzMmxMGgkf38//vKXC9i2LY/XXjuyuyimd286DBnCD9ZVZIw5A1gYnIJx485izJjO/M//LCUvr/yI9f0mTSJ73Tqyvj/6tQVjjDldWBicAhHh2WdHkZdXzpNPHvmQWe/rrsMvIMAuJBtjTnsWBqdo4MB2/OpXyUyduoYdO/IPWxcSE0O3yy5j07vvUuM++aGxjTGmpTQ4DETEJSLfichHzueuIrJCRLaLyEwRCXTKg5zP2531SfX28YhTvkVELqlXfqlTtl1EHm66w2sZTzxxHgEBfjz88DdHrOs7aRKlBw+y2wavM8acxk7mzOBuYFO9z08Dz6tqdyAPuMUpvwXIc8qfd+ohIn2B64B+wKXAX52AcQGvAGOBvsD1Tt0zRnx8OA8+OITZs7fyf/+377B1Z40bR3B0tF1INsac1hoUBiKSCIwH3nQ+CzAamO1UeRu40lme4HzGWT/GqT8BmKGqFaq6C9gODHGm7aq6U1UrgRlO3TPK/fenEh8fzr33fkVNzY/vM3AFBtL7+uvZPncuFQUFXmyhMcYcW0PPDF4AHgRqB+WJAfJVtbYjPANIcJYTgHQAZ32BU7+u/CfbHKv8CCJym4ikiUhadnZ2A5veMsLCAnnyyfNYufIAM2duPmxdv0mTcJeXs3X27GNsbYwx3nXCMBCRy4AsVV3dAu05LlV9Q1VTVTU1Li7O2805wqRJ/UhJaccjjyw5bMjrDuecQ3SvXnZXkTHmtNWQM4NzgStEZDeeLpzRwItAlIj4O3USgdrO8n1AJwBnfSSQW7/8J9scq/yM4+fnudV0z55CfvObhXXdRSJC30mTyPjmG/J3NfztacYY01JOGAaq+oiqJqpqEp4LwItU9UbgK+Bqp9pkoHaIzvnOZ5z1i9TzUuD5wHXO3UZdgR7ASmAV0MO5OynQ+Y75TXJ0XjB6dGcee2w406dv5J57FtW9D7nvTTcB8P2rr3qzecYYc1T+J65yTA8BM0TkT8B3wN+d8r8D/xCR7cAhPL/cUdWNIjIL+AFwA3eoajWAiNwJLABcwDRV3XgK7fK6xx4bQXFxFc8+m0Z4eCD/+78jadO5M30nTWLVM8+QOHIk3S6/3NvNNMaYOlL7l+uZJjU1VdPS0rzdjGNSVX7zmy94/fXvefLJ83j00WFUlZUx4/zzObR5MzcsW0ZccrK3m2mM8SEislpVU4+2zp5AbiYiwl//+jNuuqkvv/vdt0yduoaAkBCunDuXwIgI5lx+OaU5Od5upjHGABYGzcrPT3jrrUu56qoe3H33IqZNW09EQgJXzp1LSWYm86++murKSm830xhjLAyam7+/H++9N55LLkni1lsX8Le/raPDOedw6bRpZCxezJd33cWZ2lVnjGk9LAxaQFCQPx98MIExY7pw222fc8MNHxM//ucMfeQR1r3xBt+98oq3m2iM8XEWBi0kNDSAzz77OU88cS7vv7+FlJS38b/st3SfMIGv7rmH3Z9/7u0mGmN8mIVBC3K5/Pj974ezZMn1AIw8fybrBvwXbfv049/jxvHVffdRWVTk5VYaY3yRhYEXDB8ez9q1k7n22l489sQqpkc+QIfrbmf1888zrU8ftsyebdcRjDEtysLASyIjg3j33fG8/fZYvvs+l1tmd2Pdle9Q1KYrH15zDf8eO5a87du93UxjjI+wMPAiEWHSpH6sWzeZSZP6MfPjbB7eciWfD3qWFUt2Mj05mf977DHrOjLGNDt7Avk0kplZzIsvruHVV9dSWFhJSvtCzj74PsnReZz78H0MuuMOAkJDvd1MY8wZ6nhPIFsYnIYKCip4/fXveeGF1WRmluCSGjrrbnqHHeSKm0dy4xO3EtE23NvNNMacYSwMzlAVFW4WLdrL11+ns+DDH1i3qRhF8MdN/26BXHhZf0aM7MLQoR1JTIzwdnONMac5C4NWorCwgg9e+YTZL3/Kuv3B7Ceeamfg2fiOYQwdFs+QIR3o1SuaLl3akJTUhrZtg/G8ddQY4+ssDFoZVWX/0qWs+9dMvpqxhK2Hwkh3ncX+kJ4cKA4+rG54eABdurShS5c2xMeH065dKO3ahRIXF1q33LlzBFFRwcf4NmNMa2Fh0IrVVFeTsWQJW2bOZOvs2eTmlJDnaod2Pwd3pwGUtulCbmUYezNKOHCghOzsUqqrj/xv3rt3NMOGdWT48HiGDYunX78YXC672cyY1sTCwEfUuN1kfPMNe774gr2LFnFg1Sq0pgZXUBAJ555L+9RU2nQ9C2mXRFVkR0r8IsnJLWfLljxWrMhk2bL95OSUAZ4zikGD2tOpUwTx8WHEx4cTHx9OQoLn7KKqqobS0ipKSqooLXU78ypcLj+CglwEB/sTFOSqWy4rqyIrq5SsrFIOHiytWy4pqSI0NIDQUP+6eVhYAOHhgf3OMvEAABRASURBVMTEBBMbG1I3xcR4psBAl5f/pY05M1kY+KiKwkIylixh76JFpC9aRO4PPxw2ZLZfQACRSUm06dKF0HbtCI6NI88Vx7bCKH7IDGTrfsgphP37SygvdzdZu/z8hLi4ENq1CyUsLICyMvcRoVJVVXPM7UND/YmMDPrJFEivXtGMGOE5s2nb1rq9jPkpCwMDeLqUivftI3/HjsOmovR0yrKzKc3KOuIBt5C4OLqOHUfshWMJ6DOUnEI4eLCUwEA/QkMDCAvzTLV/2dfUKOXlbioqqikvr3bmboKD/Wnf3nONIjo6+IRdUBUVbnJzy8nJKXOm0rrlgoIKCgoqKSz0zAsKKsjLK2fHjvy6LrDevaMZPjyeESPiSUlpR9eukURH28V049ssDEyDucvLKc3Opiw7m0ObN7Pzk0/Y9cknlOfl4RcQQOL553PW+PF0SE0lpl8/QqKjvd3kOsXFlaxadYBly/azdOl+li3bz6FD5XXrw8MDSEqKJCmpDUlJkcTEBFNY6AmT/PyKunlFRTV9+kRz9tntGTSoHYMGtaNduzAvHpkxTcPCwJySGreb/cuWseOjj9j50Ufk/vBD3bqwjh2JTU4mtl8/YpOTienbl+jevQlu29aLLfZQVbZty+OHH3LZvbuQ3bsL6ua7dhVQWFhJWFgAUVGerqbaub+/Hxs25LBrV0HdvhISwjn77Pace248o0Z15uyz2xEQcOxrF8XFlXz/fTaRkYEkJ8e1xOEac0IWBqZJFe3bR8769eRs2OCZNm4kd+NG3GVldXVC27cnundvYvr0IaZPHyK7diW0QwfCO3YktF07XIGBXjwCj+rqmuN2V+XllbN2bRbffZfFmjUHWb36IJs3HwIgLCyA885LYNSoTlxwQScqK6vr6qxefZAtWw5R+7/WDTf04amnRtK5c5uWOCxjjsnCwDQ7ramhYNcucjdtInfTJg5t3swhZ7kiP/+I+iExMYR17EhEp07E9O1LTL9+xPbrR0zfvgSGn75DbRw8WMI332SweHE6X3+dzsaNuYetT0gIZ/Dg9gwe3J5Bg9qzYkUmzz7r+Tm9775UHnpoCBER3g9C45ssDIzXqCqlWVkU7t1L6YEDFGdmUnLggGfKzKRw925yN22iuqKibps2SUnE9OlDeHw8oe3bE9ahQ90U2r494fHxp01gZGWV8O23+wgO9mfw4Pa0b3/ktYW9ewt59NElvPvuJjp0CONPfzqPm2/uR2mpmx9+yGXjxhxnymXfvmLGju3KLbf0p1ev0+d6jGkdLAzMaa2mupqCnTsP63LK27rVExgHD6LV1UdsExgRQXh8PGHx8YQ7U0y/fsQPG0bbHj0Qv9PvgbkVKzK5996vWLp0P1FRQeTn/xiAwcH+9O4dTUxMMIsXZ+B21zByZCK33tqfq6/uSWhogBdbfqTS0iree28zubllDBgQx8CBcXToENakd2uVlVUxb94OVJX+/WPp1Sv6uNdpzIlZGJgzltbUUJabS8mBA5QePOg5s8jMpHj/for376fEmRfv21f3DEVw27Z0GDqU+GHD6DhsGPHDhhEUGenlI/FQVd5/fwuffbab7t2j6Ncvln79YujaNbLu+sWBAyW8885G3nxzPdu25dGmTSA33tiHu+8e7PWzhX37injllbW8/vr3h92pBRAbG8LAgZ5gGDYsnssuO4uQkJMPsb17C3n11bX87W/ryc398TpUQIAfvXtHk5wcS//+cQwf3pGRIxPtSfmTYGFgWr2a6moObd5M5vLl7F++nMzly8nZuBFUET8/OgwZQpeLLqLLz35G/LBhp8UF7BNRVZYsyeDNN9fz/vtbqays5uab+/GHPwynS5eWDbdVqzJ54YU1zJq1hZoa5coru/Nf/zWYfv1iWbcum++/z3bmWWzYkEt5uZuoqCBuuKEPv/pVMoMHtz/uWYOqsnhxOi+99B1z53re8HfFFd24885BxMWFsn59NuvX57BhQw7r12ezd6/neZh27UKZOLEH11zTi/PPT8Tf/9SDIT+/nG3b8ti6NY99+4rJzvY8LZ+dXebMS6mpgcTEcBITI5zJsxwZGcTBgyXs31/C/v3FZGYWs39/CXl55Qwe3J6f/awLY8Z0plOnxt1MkJlZzObNh7jwws6N2t7CwPikisJCDqxcSfrixexZuLBueA7/0FA6XXABnUaNIm7AAGL79yc8Pv60fiAtK6uEp55ayV//uhaA228fyKOPDj3qNYqmoKps3JjDRx/tZM6cbaxceYCIiEBuvbU/d901iK5do465rdtdwzffZDBt2nr+/e9tlJe76d8/ll//uj9XXdWdgoJKdu8uYM+eH2/33bAhh61b84iODubWW/vz29+mHDfw8vPL+eKLPbz//lY++mgHpaVu4uJCuOqqHlx4YWeqqqopKak6bCorc+Ny+eFyCf7+fs4kiAh79xaydasnALKySg/7rpAQ/7on5msHeATYt6+YjIwi0tOLKCmpOqKNkZFBdUO5hIUFsGzZfrKzPWc6PXu2rQuGlJR2dO7c5qhBpqqsW5fN/Pk7+PDDHaxadYDo6GAOHvxto4LPwsAYoDw/n/Svv2bPF1+wZ+FC8rZurVsXFBXleV6if3/iBgyg8+jRnmsPp1lApKcX8sQTy5k2bT1BQS7uvnswV1/dk6AgF4GBLgID/Zy5p2+9oqKasjI35eW1UzVud40z/pNnDKjaudtdw+LF6Xz44Q4++mgne/YUAjBoUDsmTerHr3+dTJs2QSfV3vz8cmbO3MK0aetZufLAEetDQvxJSmpD166RTJzYkxtu6H3SXUulpVV8+uku3n9/Cx99tPOov5iDglyEhPhTU6NUVytudw1ud03dE+sdOoTRs2fbelM0PXu2pXPnCMLCjn8WqaoUFlaSkVFEfn4FHTqE0bFj2BHXeWpqlA0bcvjyyz188cUeFi/OqGurv78fXbq0oVu3KLp1i6Rbtyh27Spg/vwdpKd7zoKGDu3I5Zd344orupGcHNuon00LA2OOoiw3l5yNGw9/ZmL9eioKPA+bRXbtStIll9D10kvpPHo0gRGnzwuEtm3L47HH/o/33tvcZPsUAVXPL+iLLurCZZd1Y9y4riQkNM1xb9yYw6JFe+nQIazuKfDY2JAmDdzS0iq2bcurGyolPDyA0NCAY/4VrarU1KhXrjtUVlaTlnaAzZsPsWNHPtu357Njh2fKz68gJMSfiy9O4vLLuzF+/Fl06HDqZ4EWBsY0kKpSsHMnuz//nF2ffcbeRYuoKi7Gz9+f+BEjiOnbl4hOnX6cEhOJSEzEP9g7A+Nt3pzLli15VFZW100VFdVUVtagqoSE+BMc7E9wsMuZ++Pv70dpaRXFxVUUF1fWzSsqqhkxIp5Rozo16sKvaTqHDpURGhpAcLB/k+7XwsCYRqqurGTf0qXsXrCAvV9+Sf6OHZQfOnREvciuXWmfmkr7wYPpkJpK+7PPPi2G5DCmPgsDY5pQVWkpRRkZFKWnU5SeTuHeveRs2MDBtDQKdu2qqxfVrZtnnKaYGEJiYgiOjq6bh3XsSLuUFILa2BAVpuUcLwya9hzEGB8QEBpKdM+eRPfsecS6stxcDq5Zw8G0NA6kpZG/YwfZ69dTnptLVUnJ4ZVFiOnThw5DhtBx6FA6DhlCbP/+uAKsi8a0PDszMKaFuCsqqMjLo+zQIQr37OHAqlUcWLmSzJUrKcvOBkBcLgJCQ3EFBuIXGIirdgoKIn7ECHpffz2JI0fi57Incc3Js24iY05jqkrhnj1krlxJzrp1VJWWUl1ZSU1lJdXOVFlYyN6vvsJdWkpYx470/sUv6H3ddXQYMuS0u/3VnL4sDIxpBSpLStj58cdsfu89dn3yCdWVlUR27UrCuecSEhdHaFwcIXFxhMTGEhoXR3hCAm06dz4tx2ky3mFhYEwrU1FQwLa5c9kycya5mzZRlp195DUJwD8khOhevYju3Zto590SbZKSULcbd3k57vJyqsvLqa6ooLqqioiEBKK6dyciMdFCpBU6pTAQkWDgGyAIzwXn2ar6mIh0BWYAMcBq4JeqWikiQcA7wGAgF/iFqu529vUIcAtQDUxR1QVO+aXAi4ALeFNV/3yig7IwMOZwVWVllOXkUJadTVlODoV793reLeG8V6Jwzx5o4B9/rqAgIrt2Jap7d6K6dfM8cCeeoRvqz/1DQgiKjCQoKoqgyEiCo6IIjIwkMDwcP39/xOVCXK66ZT9/f1yBgSfs2qqprsZdWkpVaSn+ISEERkScUneYqqLV1fj5H/+eGa2poTQnhxJnqHX/4GAiEhMJT0jw2rMkTelU7yaqAEararGIBADfisinwL3A86o6Q0Rew/NL/lVnnqeq3UXkOuBp4Bci0he4DugHxANfiEjt7RivABcBGcAqEZmvqj9gjGmwgJAQAjp1ok2nTkddX1VaSt7WrRSlp+MXGIh/cDD+wcG4goNxBQUhfn4UpaeTv2MH+du3183Tv/qKqtLSBgdJQ7iCguq+2z84GFdgoOdMpbSUqpIS3OWHj4jqCgwktF27w7rD/ENCPNdUKiqoqazEXTsvL6eqpISq4mKqSkqodOZaXY1fQACBEREEhIcTGBFBYHg4AWFhVOTnU5yZSWlW1lGHTAcIiY31BENiIiExMZ5wc7kQP78fQ8/lwi8goG5yOXNxuagsKqIiP79uKs/Pp7KggNAOHYipd+YW3acPobGxqCplOTkc2rKFvC1bOLR1K3lbtlDjdjPxo4+a7L9FrROGgXpOHYqdjwHOpMBo4Aan/G3gj3jCYIKzDDAbeFk8kT4BmKGqFcAuEdkODHHqbVfVnQAiMsOpa2FgTBMKCA2lXUoK7VJSjlknumdPuowZc9z9qCqoojU1uMvLqSgo8PyCKyioW6795VvjdlPjdh+2XF1RUdc9VddVVVGBf3AwAWFhh03+oaG4S0spzcqiNDubsuxsSrOzObR1K9UVFbiCgurutqqd+wcHE9y2rWcfzi/7gLAw/IODqSotpbKoiKri4h/nxcWEduhAXEqK57Ws9V6mVF1RQVFGBsW1z5U48+x169DqarSmxjOvrqamdl5VRXVV1VFDpf5ZVFBUFOEJCRTv20fG4sWHvTY2JDYWra6mPC+vrswVGEhU9+7EJiejqk1+40CDnjMQEReerqDueP6K3wHkq6rbqZIBJDjLCUA6gKq6RaQAT1dSArC83m7rb5P+k/Khx2jHbcBtAJ07N24IV2PMqanrKvLzIzA8nMDwcCISEk68oY/RmhpP+DnBEBAWdsxbgrWm5rBuvUObNyMuF9G9etG2Vy+ie/akTVJSs95S3KAwUNVqIEVEooA5QO9ma9Hx2/EG8AZ4rhl4ow3GGNMQ4udX95xIQ+pGJiURmZTEWWPHtkDrjnRStwuoaj7wFTAciBKR2jBJBPY5y/uATgDO+kg8F5Lryn+yzbHKjTHGtJAThoGIxDlnBIhICJ4LvZvwhMLVTrXJwDxneb7zGWf9Iue6w3zgOhEJcu5E6gGsBFYBPUSkq4gE4rnIPL8pDs4YY0zDNKSbqCPwtnPdwA+YpaoficgPwAwR+RPwHfB3p/7fgX84F4gP4fnljqpuFJFZeC4Mu4E7nO4nROROYAGeW0unqerGJjtCY4wxJ2QPnRljjI843nMG9oihMcYYCwNjjDEWBsYYY7AwMMYYwxl8AVlEsoE9jdw8FshpwuacKey4fYsdt29pyHF3UdW4o604Y8PgVIhI2rGuqLdmdty+xY7bt5zqcVs3kTHGGAsDY4wxvhsGb3i7AV5ix+1b7Lh9yykdt09eMzDGGHM4Xz0zMMYYU4+FgTHGGN8KAxG5VES2iMh2EXnY2+1pTiIyTUSyRGRDvbJoEVkoItuceVtvtrGpiUgnEflKRH4QkY0icrdT3qqPG0BEgkVkpYh87xz7/zjlXUVkhfMzP9MZJr5VERGXiHwnIh85n1v9MQOIyG4RWS8ia0UkzSlr9M+6z4SBMwT3K8BYoC9wvYj09W6rmtV04NKflD0MfKmqPYAvnc+tiRu4T1X7AsOAO5z/xq39uAEqgNGqOhBIAS4VkWHA08DzqtodyANu8WIbm8vdeN6xUssXjrnWhaqaUu/5gkb/rPtMGABDgO2qulNVK4EZwAQvt6nZqOo3eN4nUd8E4G1n+W3gyhZtVDNT1UxVXeMsF+H5BZFAKz9uAPUodj4GOJMCo4HZTnmrO3YRSQTGA286n4VWfswn0OifdV8KgwQgvd7nDKfMl7RX1Uxn+QDQ3puNaU4ikgQMAlbgI8ftdJesBbKAhcAOIF9V3U6V1vgz/wLwIFDjfI6h9R9zLQU+F5HVInKbU9bon/WGvOnMtEKqqiLSKu8rFpFw4N/APapa6Plj0aM1H7fz5sAU5zW1c4DeXm5SsxKRy4AsVV0tIqO83R4vOE9V94lIO2ChiGyuv/Jkf9Z96cxgH9Cp3udEp8yXHBSRjgDOPMvL7WlyIhKAJwjeVdUPnOJWf9z1qWo+nneUDweiRKT2j77W9jN/LnCFiOzG0+07GniR1n3MdVR1nzPPwhP+QziFn3VfCoNVQA/nToNAPO9mnu/lNrW0+cBkZ3kyMM+LbWlyTn/x34FNqvpcvVWt+rgBRCTOOSNAREKAi/BcM/kKuNqp1qqOXVUfUdVEVU3C8//zIlW9kVZ8zLVEJExEImqXgYuBDZzCz7pPPYEsIuPw9DG6gGmq+qSXm9RsROQ9YBSeYW0PAo8Bc4FZQGc8w39fq6o/vch8xhKR84AlwHp+7EN+FM91g1Z73AAiMgDPBUMXnj/yZqnq4yJyFp6/mqOB74CbVLXCey1tHk430f2qepkvHLNzjHOcj/7Av1T1SRGJoZE/6z4VBsYYY47Ol7qJjDHGHIOFgTHGGAsDY4wxFgbGGGOwMDDGGIOFgTHGGCwMjDHGAP8fUJhAZ4lRPPsAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["train_loss_ysd = np.sqrt(np.array(seq_train_loss))\n","test_loss_ysd = np.sqrt(np.array(seq_test_loss))"],"metadata":{"id":"zQ4jdxFPAgfR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# With Gangnam and Seocho\n","plt.title('GCN Loss')\n","plt.plot(train_loss_ysd,color='darkred',label='Train Loss')\n","plt.plot(test_loss_ysd,color='darkblue',label='Test Loss')\n","plt.legend()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"q2eS2NxEE837","executionInfo":{"status":"ok","timestamp":1665039343777,"user_tz":-540,"elapsed":997,"user":{"displayName":"namhun kim","userId":"12332195563700468765"}},"outputId":"84159557-812a-4f0a-f03a-de1f88d69c09"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7fbc02563950>"]},"metadata":{},"execution_count":112},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["M = torch.load('/content/drive/Shareddrives/DSL_Modeling_E/...')\n","M.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZdTrtYoxFAjq","executionInfo":{"status":"ok","timestamp":1665048947214,"user_tz":-540,"elapsed":570,"user":{"displayName":"namhun kim","userId":"12332195563700468765"}},"outputId":"70c20040-c44a-4686-987e-1051be886328"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (emb_goods): Linear(in_features=11, out_features=5, bias=True)\n","  (emb_direc): Linear(in_features=8, out_features=2, bias=True)\n","  (conv1): GCNConv(17, 24)\n","  (conv2): GCNConv(24, 20)\n","  (fc1): Linear(in_features=20, out_features=15, bias=True)\n","  (fc2): Linear(in_features=15, out_features=10, bias=True)\n","  (fc3): Linear(in_features=10, out_features=5, bias=True)\n","  (fc4): Linear(in_features=5, out_features=3, bias=True)\n","  (depos_output): Linear(in_features=3, out_features=1, bias=True)\n","  (month_output): Linear(in_features=4, out_features=1, bias=True)\n","  (ReLU): ReLU()\n",")"]},"metadata":{},"execution_count":26}]}]}